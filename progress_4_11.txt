Checked the 1-1/2(d)^2 in Fast Approximate Correlation for Massive Time-series Data and confirmed it was Euclidean distance^2
Fixed code for top 500 clusters number counts that matches 
    Count1: values on the left larger than 0.000001
    Count2: count of values on the right smaller than 1.34
    Count3: count of values on the left larger than 1.48
    This took me ~2 days because I had a huge bug in creating subject kmeans code, and that I had to run 2 spark jobs to finish everything. Up to this point, the code is still running 
    command is in plots.bash where bash uses a sequence of number to run the corr_matrix_subject.py in order to get our count numbers
Fixed db_storage_spec.docx
    Still need to consider cases where we have more than 2 time series. How do we want to deal with this situation. 
